{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a04bcd7-931d-4894-be60-8e91cbd61de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0747cf85d5e4967933ac342664c131b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\medin\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b63845848145b2b2c5c574778e5dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d9189203a945efb2ae1c3c1a46c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d49afc73c84fe880bb4c8d03224d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4cb8bccb314a2180aa131d8403f300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5483a3b35ed844aca8d9d29024ae0715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaeb28b6a184517a6cbe7231f291fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e744414320014bc1a8f513328d858712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a05ab7edf2f4d708251c2dadac9696d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e867069cde64fb1b6738aaf03c48e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "dataset = dataset.map(lambda x: {'label': 1 if x['label'] == 'pos' else 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568c245-8cef-4ced-85d4-b3b6d34e2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149fcd8-f8b2-4b6c-92df-3ea1ef516c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(muestra):\n",
    "    return tokenizer(muestra['text'], padding='max_lenght', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa5431-a39c-4959-a7e0-6cc0fa2908ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenizar, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21530a57-6026-488c-9041-a8e19ea161e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76800638-45fd-4e6a-b463-3ed49964e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets['train'].shuffle(seed=42).select(range(10000))\n",
    "val_dataset = tokenized_datasets['test'].shuffle(hseed=42).select(range(1000))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640d427-c17b-44a1-8160-79edd80dbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2a1f5-9eaa-4cef-bd8e-a039f8ca1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd068079-9b46-4463-85a0-422f3a08e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd7ed2-4b19-43c6-bce8-f9f57518ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a5b4c-6d56-435d-bd52-c70a0924854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tf-keras\n",
    "# pip install transformers[torch]\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cfb74-9f89-4278-91e3-31d823909e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar memoria\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900852f6-a7c8-49aa-a2be-c83fa4d6a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TraningnArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    waight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24139999-f99a-42f5-b809-128899ad4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8126d590-90df-42f3-b8f0-841ea2771b7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m;\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51e1a0-44f3-48aa-beef-3da6d8a22f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42d886-0245-44b9-b88b-aebf22426f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff986aa-ff19-4af2-bc7e-22ac6cc97cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cp\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b68b0-3aa7-44b8-b013-db4039def8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Me encanta este producto\", \"No me gustó para nada\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e6b7b-4533-4fce-acda-4d0710b97c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3915e8-9152-4203-ab68-83981e3f7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verificar el dispositivo de un tensor dentro de 'inputs'\n",
    "print(f\"Dispositivo de los inputs (input_ids): **{inputs['inputS_ids'].device}**\")\n",
    "# 2. Verificar el dispositivo del modelo\n",
    "print(f\"Dispositivo del model: **{next(model.parameters()).device}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741e3a4-4835-4758-809b-4c6fb6c1a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373ee84-0079-49e5-839d-081523252ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=predictions.numpy())\n",
    "plt.xlabel('Sentimiento')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515daa3-4408-4dde-a1c2-e1f7d2ef1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_numpy = predictions.cpu().numpy()\n",
    "preductions_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21b2f2-1b4f-415b-91fc-9c2d31cdb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=predictions_numpy)\n",
    "plt.title('Conteo de Predicciones por Clase')\n",
    "plt.xlabel('Clase predicha')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eaa006-9ae2-44d6-ab46-729fc2336a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_en = [\n",
    "    \"Excellent quality, totally worth the price!\",\n",
    "    \"Works perfectly, I’m very satisfied with this purchase.\",\n",
    "    \"Fast delivery and great customer service.\",\n",
    "    \"Stopped working after a week, very disappointed.\",\n",
    "    \"Poor quality, not as described.\",\n",
    "    \"Shipping took forever and the product came damaged.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93adeef-5a5c-4537-9077-a8d64bf01c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_en = tokenizer(texts_en, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "outputs_en = model(**inputs_en)\n",
    "predictions_en = torch.argmax(outputs_en.logits, dim=-1)\n",
    "print(predictions_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7aff78-8c3a-4448-84d0-29e888374179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=predictions_en.numpy())\n",
    "plt.xlabel('Sentimiento')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e2fed-9fb9-43c3-b0bb-dcc8b7908613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Autotokenizer, AutoModelForSequenceClassification\n",
    "# Reemplazar el modelo base\n",
    "MODEL_NAME_ES = \"openai/whisper-large-v3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_ES)\n",
    "model = AutoModelFromSequenceClassification.from_pretrained(MODEL_NAME_ES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
